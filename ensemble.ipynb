{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5209cf86",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9dac590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# genera dataset aleatorio\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "data = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=10)\n",
    "\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef26cf",
   "metadata": {},
   "source": [
    "Modelo Base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5c48d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7929999999999999 0.03905124837953326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Creamos el modelo base, en nuestro caso un arbol de decision, lo entrenamos sobre\n",
    "# un k_fold para reducir la aleatoridad de las metricas. Fijamos el random_state para\n",
    "# poder \n",
    "model = DecisionTreeClassifier(random_state=10)\n",
    "accuracy = []\n",
    "\n",
    "for train_idx, test_idx in data.split(X, y):\n",
    "    # Entrenamos el model, predecimos y almacenamos metricas \n",
    "    model.fit(X[train_idx], y[train_idx])\n",
    "    predictions = model.predict(X[test_idx])\n",
    "    accuracy.append(accuracy_score(y[test_idx], predictions))\n",
    "\n",
    "# Imprimimos accuray y desviacion estandar para comparar\n",
    "print(np.mean(accuracy), np.std(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea9ac2",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "072b21d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8536 0.031417192745374314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_model = BaggingClassifier(model, random_state=10)\n",
    "accuracy = []\n",
    "\n",
    "for train_idx, test_idx in data.split(X, y):\n",
    "    # Entrenamos el model, predecimos y almacenamos metricas \n",
    "    bagging_model.fit(X[train_idx], y[train_idx])\n",
    "    predictions = bagging_model.predict(X[test_idx])\n",
    "    accuracy.append(accuracy_score(y[test_idx], predictions))\n",
    "\n",
    "# Imprimimos accuray y desviacion estandar para comparar\n",
    "print(np.mean(accuracy), np.std(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d790d64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8536 0.031417192745374314\n",
      "0.8682 0.02964388638488552\n",
      "0.8739999999999999 0.0295972971738975\n",
      "0.8762000000000001 0.030717421766808504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "n_estimator = [10, 25, 50, 100]\n",
    "\n",
    "for n in n_estimator:\n",
    "    bagging_model = BaggingClassifier(model, n_estimators=n, random_state=10)\n",
    "    accuracy = []\n",
    "\n",
    "    for train_idx, test_idx in data.split(X, y):\n",
    "        # Entrenamos el model, predecimos y almacenamos metricas \n",
    "        bagging_model.fit(X[train_idx], y[train_idx])\n",
    "        predictions = bagging_model.predict(X[test_idx])\n",
    "        accuracy.append(accuracy_score(y[test_idx], predictions))\n",
    "\n",
    "    # Imprimimos accuray y desviacion estandar para comparar\n",
    "    print(np.mean(accuracy), np.std(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e714f1",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c7e8dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=10)\n",
    "data = RepeatedKFold(n_splits=10, n_repeats=5, random_state=10)\n",
    "# genera datos a partir de un modelo lineal de parámetros aleatorios y adición de ruido\n",
    "\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bae04",
   "metadata": {},
   "source": [
    "Modelo base regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c2da138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.8051582738266 13.668830416742049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=10)\n",
    "errors = []\n",
    "\n",
    "for train_idx, test_idx in data.split(X, y):\n",
    "    model.fit(X[train_idx], y[train_idx])\n",
    "    predictions = model.predict(X[test_idx])\n",
    "    errors.append(mean_absolute_error(y[test_idx], predictions))\n",
    "\n",
    "print(np.mean(errors), np.std(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bd745",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23bda673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.71762606445235 7.594808697086279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagging_model = BaggingRegressor(model, random_state=10)\n",
    "errors = []\n",
    "\n",
    "for train_idx, test_idx in data.split(X, y):\n",
    "    bagging_model.fit(X[train_idx], y[train_idx])\n",
    "    predictions = bagging_model.predict(X[test_idx])\n",
    "    errors.append(mean_absolute_error(y[test_idx], predictions))\n",
    "\n",
    "print(np.mean(errors), np.std(errors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
